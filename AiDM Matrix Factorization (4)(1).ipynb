{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66e92b9f",
   "metadata": {},
   "source": [
    "# 3 Theory\n",
    "In this section, the theory behind each of the used concepts and algorithms will be explained with their relevant equations. We will first explain the concept behind cross-validation and how it applies to our data. Then we will describe the 5 algorithms, starting with the four approaches classified as 'naive' because they are relatively easy and quick to calculate and implement, and because they work surprisingly well. These naive approaches however cannot be used for the normalization of ratings and the cumulative improvement of the RMSE, so we will also evaluate two other approaches. \n",
    "\n",
    "## 3.1 Cross-validation\n",
    "To make sure that our results are reliable, we are interested in the accuracy of our model on data that was not used in the training process, and we will apply the 5-fold cross-validation scheme to achieve this. The whole data set is randomly split into 5 parts of more or less equal sizes, and we will then develop 5 models for each combination of 4 our of 5 parts. Each of the 5 parts is therefore used once as a test set, while the model is trained on the remaining 4 sets. Each of the obtained models is then tested to the test set that was not used to train the model. This way we generated 5 different estimates of the model accuracy, and their average is considered to be a good estimate of the error on the future data. <br>\n",
    "In this assignment, our training sets consist of ~800.000 ratings, and we will test the created model on the remaining ~200.000 ratings (test set). This was done 5 times to the completely unique test sets (this means that if all 5 test sets are combined, we obtain the total data set consisting of ~1.000.000 ratings again).\n",
    "\n",
    "## 3.2 Naive Approaches\n",
    "The following formulas that represent the 5 naive approaches were taken from slide 17.\n",
    "### 3.2.1 Naive Approach 1:Global Average Rating\n",
    "$\\;\\;\\;\\;\\;\\;$ $X\\approx U\\cdot M$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eb3a51",
   "metadata": {},
   "source": [
    "## 3.4 Matrix factorization\n",
    "\n",
    "The idea behind matrix factorization is similar to that of UV matrix decomposition discussed earlier. We will follow the approach taken in the paper [$\\textit{gravity-Tikk.pdf}$](https://www.cs.uic.edu/~liub/KDD-cup-2007/proceedings/gravity-Tikk.pdf) (2007). Here our goal is also to approximate the matrix with ratings, now called X, as the product of two matrices U and M:<br>\n",
    "### $\\;\\;\\;\\;\\;\\;$ $X\\approx U\\cdot M$, $\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$(1)<br>\n",
    "where U is an I x K and M is a K x J matrix, so that u$_{ik}$ and m$_{kj}$ can be treated as the kth feature of the ith user and the jth movie respectively. The major differences with the UV decomposition is that we update the matrices U and M differently, and that they are also initialized differently. <br>\n",
    "<br>\n",
    "We first initialize the two matrices U and M by filling them with values between 0 and 1. We then iterate over each known rating element of X and compute the training error on the (i, j)th example:<br>\n",
    "### $\\;\\;\\;\\;\\;\\;$ e$_{ij}$ = x$_{ij}$ - $ \\sum_{k=1}^{K} u_{ik}m_{kj}  $, $\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$(2)<br>\n",
    "where e$_{ij}$ is the training error on the (i, j)th example and x$_{ij}$ is an element in the matrix X. u$_{ij}$ and m$_{ij}$ denote the elements of U and M, so the sum in eq.2 denotes how the ith user would rate the jth movie according to the model. <br>\n",
    "To minimize the RMSE, we have applied a simple gradient descent method to find a local minimum. The gradient of $e^2_{ij}$ is given by:<br>\n",
    "### $\\;\\;\\;\\;\\;\\;$ $\\frac{\\partial}{\\partial u_{ik}}e^2_{ij} = -2 e_{ij} \\cdot m_{kj} $, $\\frac{\\partial}{\\partial m_{kj}}e^2_{ij} = -2 e_{ij} \\cdot u_{ik} $$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$(3)<br>\n",
    "We then updated the weights in U and M in the opposite direction of the gradient to decrease the error, thereby better approximating x$_{ij}$. Furthermore, a regularization which prevents large weights is implemented to obtain a better prediction for unseen examples. The updated elements can now be calculated according to eq.3:<br>\n",
    "### $\\;\\;\\;\\;\\;\\;$ u'$_{ik}$ = u$_{ik}$ + $\\eta$(2e$_{ij}$m$_{kj}$ - $\\lambda$u$_{ik}$$)$, $\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$(4)<br>\n",
    "### $\\;\\;\\;\\;\\;\\;$ m'$_{kj}$ = m$_{kj}$ + $\\eta$(2e$_{ij}$u$_{ik}$ - $\\lambda$m$_{kj}$$)$, $\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;\\;\\;\\;\\;$$\\;\\;$(5) <br>\n",
    "where $\\eta$ is the learning rate and $\\lambda$ is the regularization.\n",
    "\n",
    "We through each known element of X which is not in the probe subset and apply eq.6 & 7 to update U and M. After each loop the RMSE w.r.t. the probe subset is computed to see if it has improved (i.e. decreased) from the previous iteration. For this assignment, we used a dimension of K=10 for the matrices U and M, a regularization of r=0.05, a learling rate of l=0.005 and a stop at 75 iterations through the loop. If the RMSE did not improve during two iterations, the loop is also terminated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83dd42c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3781e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Users data\n",
    "usersData = pd.read_csv('users.dat', sep='::', header=None, names=['UserID', 'Gender', 'Age', 'Occupation', 'Zip-code'], engine='python')\n",
    "\n",
    "#Ratings data\n",
    "ratingsData = pd.read_csv('ratings.dat', sep='::', header=None, names=['UserID', 'MovieID', 'Rating', 'Timestamp'], engine='python')\n",
    "ratings_testData = pd.read_csv('ratings_test.dat', sep='::', header=None, names=['UserID', 'MovieID', 'Rating', 'Timestamp'], engine='python')\n",
    "\n",
    "#Movies data\n",
    "moviesData = pd.read_csv('movies.dat', sep='::', header=None, names=['MovieID', 'Title', 'Genres'], engine='python', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "687b0087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserID Gender  Age  Occupation Zip-code\n",
      "0       1      F    1          10    48067\n",
      "1       2      M   56          16    70072\n",
      "2       3      M   25          15    55117\n",
      "3       4      M   45           7    02460\n",
      "4       5      M   25          20    55455\n",
      "   UserID  MovieID  Rating  Timestamp\n",
      "0       1     1193       5  978300760\n",
      "1       1      661       3  978302109\n",
      "2       1      914       3  978301968\n",
      "3       1     3408       4  978300275\n",
      "4       1     2355       5  978824291\n",
      "   UserID  MovieID  Rating  Timestamp\n",
      "0       1     1193       5  978300760\n",
      "1       1      661       3  978302109\n",
      "2       1      914       3  978301968\n",
      "3       1     3408       4  978300275\n",
      "4       1     2355       5  978824291\n",
      "   MovieID                               Title                        Genres\n",
      "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
      "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
      "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
      "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
      "4        5  Father of the Bride Part II (1995)                        Comedy\n"
     ]
    }
   ],
   "source": [
    "#Users data\n",
    "print(usersData.head())\n",
    "\n",
    "#Ratings data\n",
    "print(ratingsData.head())\n",
    "print(ratings_testData.head())\n",
    "\n",
    "#Movies data\n",
    "print(moviesData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b668606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_UM(X_train, K):\n",
    "    \"\"\"\n",
    "    This function initializes two matrices U and V for the UV-decomposition\n",
    "    \"\"\"\n",
    "    \n",
    "    I, J = X_train.shape\n",
    "    U_i = np.random.rand(I, K) #U is an I x K matrix with randomly distributed weights \n",
    "    M_i = np.random.rand(J, K) #M is an K x J matrix with randomly distributed weights \n",
    "\n",
    "\n",
    "    \n",
    "    return U_i, M_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c212c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_elements(X_train, K, num_iter, r, l, U, M):\n",
    "    \"\"\"\n",
    "    Perform a single round of optimization for the U and M matrices using the equations from page 346.\n",
    "    The first two loops for U and M is for looping through all elements in the matrix,\n",
    "    and the loops over j/i and k represent the sums in the expressions for x and y. \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    I, J = X_train.shape\n",
    "\n",
    "\n",
    "    for i in range(I):\n",
    "        for j in range(J):\n",
    "            if X_train[i, j] >0: #i.e. non-NaN\n",
    "                eij = X_train[i, j] - np.dot(U[i, :], M[j, :])\n",
    "                #eij denotes the training error on the (i, j)th example\n",
    "\n",
    "                for k in range(K):\n",
    "                    #For all latent features, apply eq.6&7 in gravity-Tikk.pdf\n",
    "                    U[i, k] = U[i, k] + l * (2 * eij * M[j, k] - r * U[i, k])\n",
    "                    M[j, k] = M[j, k] + l * (2 * eij * U[i, k] - r * M[j, k])\n",
    "\n",
    "    return U, M\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3b2f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold number: 1\n",
      "Time at start of fold number 1  : 2023-10-21 18:48:00\n",
      "Training set:\n",
      "[[ 5. nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [ 3. nan nan ... nan nan nan]]\n",
      "Test set:\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "loop number 1 RMSE: 1.0194382083749316\n",
      "loop number 2 RMSE: 0.9379355836672594\n",
      "loop number 3 RMSE: 0.9350160401266857\n",
      "loop number 4 RMSE: 0.9319117418255155\n",
      "loop number 5 RMSE: 0.9266869762004475\n",
      "loop number 6 RMSE: 0.9202914870494888\n",
      "loop number 7 RMSE: 0.9144582294462785\n",
      "loop number 8 RMSE: 0.9095719369799069\n",
      "loop number 9 RMSE: 0.9054251317118147\n",
      "loop number 10 RMSE: 0.9018391333597123\n",
      "loop number 11 RMSE: 0.8987171052596992\n",
      "loop number 12 RMSE: 0.8960008497695284\n",
      "loop number 13 RMSE: 0.8936397508688514\n",
      "loop number 14 RMSE: 0.8915848423028196\n",
      "loop number 15 RMSE: 0.8897918836305234\n",
      "loop number 16 RMSE: 0.8882234151046164\n",
      "loop number 17 RMSE: 0.8868485688776929\n",
      "loop number 18 RMSE: 0.8856418326370163\n",
      "loop number 19 RMSE: 0.8845817354364081\n",
      "loop number 20 RMSE: 0.8836498451654764\n",
      "loop number 21 RMSE: 0.8828301083363457\n",
      "loop number 22 RMSE: 0.8821084359227453\n",
      "loop number 23 RMSE: 0.881472433933573\n",
      "loop number 24 RMSE: 0.8809112092677377\n",
      "loop number 25 RMSE: 0.8804152120857248\n",
      "loop number 26 RMSE: 0.8799760961075435\n",
      "loop number 27 RMSE: 0.8795865893356994\n",
      "loop number 28 RMSE: 0.8792403730497982\n",
      "loop number 29 RMSE: 0.878931969106631\n",
      "loop number 30 RMSE: 0.8786566361807358\n",
      "loop number 31 RMSE: 0.8784102754736338\n",
      "loop number 32 RMSE: 0.8781893460706798\n",
      "loop number 33 RMSE: 0.8779907897598415\n",
      "loop number 34 RMSE: 0.8778119648401691\n",
      "loop number 35 RMSE: 0.8776505882610109\n",
      "loop number 36 RMSE: 0.8775046853348409\n",
      "loop number 37 RMSE: 0.8773725462348477\n",
      "loop number 38 RMSE: 0.8772526885012455\n",
      "loop number 39 RMSE: 0.8771438248202437\n",
      "loop number 40 RMSE: 0.8770448353949366\n",
      "loop number 41 RMSE: 0.8769547442898173\n",
      "loop number 42 RMSE: 0.8768726991955781\n",
      "loop number 43 RMSE: 0.8767979541250915\n",
      "loop number 44 RMSE: 0.8767298546129522\n",
      "loop number 45 RMSE: 0.8766678250483503\n",
      "loop number 46 RMSE: 0.8766113578235902\n",
      "loop number 47 RMSE: 0.8765600040274767\n",
      "loop number 48 RMSE: 0.8765133654542616\n",
      "loop number 49 RMSE: 0.876471087734583\n",
      "loop number 50 RMSE: 0.8764328544254079\n",
      "loop number 51 RMSE: 0.876398381921778\n",
      "loop number 52 RMSE: 0.8763674150746051\n",
      "loop number 53 RMSE: 0.8763397234166195\n",
      "loop number 54 RMSE: 0.8763150979133104\n",
      "loop number 55 RMSE: 0.8762933481677695\n",
      "loop number 56 RMSE: 0.8762743000184923\n",
      "loop number 57 RMSE: 0.8762577934774324\n",
      "loop number 58 RMSE: 0.8762436809626284\n",
      "loop number 59 RMSE: 0.8762318257856326\n",
      "loop number 60 RMSE: 0.876222100858986\n",
      "Training matrix M:\n",
      " [[ 5. nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [ 3. nan nan ... nan nan nan]]\n",
      "Predicted matrix P:\n",
      " [[4.14193405 3.64315654 3.33475755 ... 4.25415502 3.19744522 3.60571391]\n",
      " [3.76811817 3.14094821 3.10460201 ... 3.62577866 3.40393774 3.14905473]\n",
      " [3.7401587  3.26407352 4.12303494 ... 4.22631182 3.6713313  4.07307737]\n",
      " ...\n",
      " [3.70621382 3.42151629 3.05940019 ... 3.15521016 3.76847432 3.5415615 ]\n",
      " [3.80561436 2.92115618 2.42381928 ... 3.46412111 3.78947885 3.29183719]\n",
      " [3.31721064 1.82232865 1.38881022 ... 3.26924922 4.36704868 3.3623531 ]]\n",
      "RMSE estimate of fold number  1 :  0.876222100858986\n",
      "\n",
      "Fold number: 2\n",
      "Time at start of fold number 2  : 2023-10-21 19:44:31\n",
      "Training set:\n",
      "[[ 5. nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Test set:\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [ 3. nan nan ... nan nan nan]]\n",
      "loop number 1 RMSE: 1.019621464829566\n",
      "loop number 2 RMSE: 0.9398219026463034\n",
      "loop number 3 RMSE: 0.9361644138044607\n",
      "loop number 4 RMSE: 0.932525987842868\n",
      "loop number 5 RMSE: 0.9269069152265389\n",
      "loop number 6 RMSE: 0.9207457178257583\n",
      "loop number 7 RMSE: 0.9154607167047906\n",
      "loop number 8 RMSE: 0.9110585783203706\n",
      "loop number 9 RMSE: 0.9072255443915821\n",
      "loop number 10 RMSE: 0.9037872275239432\n",
      "loop number 11 RMSE: 0.9006920450803821\n",
      "loop number 12 RMSE: 0.8979350636573239\n",
      "loop number 13 RMSE: 0.8955118233867011\n",
      "loop number 14 RMSE: 0.8934050489124704\n",
      "loop number 15 RMSE: 0.8915869782357496\n",
      "loop number 16 RMSE: 0.8900248407909425\n",
      "loop number 17 RMSE: 0.8886850376739743\n",
      "loop number 18 RMSE: 0.8875355878359592\n",
      "loop number 19 RMSE: 0.8865473837260588\n",
      "loop number 20 RMSE: 0.885694730921733\n",
      "loop number 21 RMSE: 0.8849554568271375\n",
      "loop number 22 RMSE: 0.8843107595134099\n",
      "loop number 23 RMSE: 0.8837449094635514\n",
      "loop number 24 RMSE: 0.8832448820929574\n",
      "loop number 25 RMSE: 0.8827999735572228\n",
      "loop number 26 RMSE: 0.882401432757949\n",
      "loop number 27 RMSE: 0.8820421277764376\n",
      "loop number 28 RMSE: 0.8817162546734739\n",
      "loop number 29 RMSE: 0.8814190899486068\n",
      "loop number 30 RMSE: 0.8811467840882455\n",
      "loop number 31 RMSE: 0.8808961917183814\n",
      "loop number 32 RMSE: 0.880664733222142\n",
      "loop number 33 RMSE: 0.8804502827634427\n",
      "loop number 34 RMSE: 0.8802510781169617\n",
      "loop number 35 RMSE: 0.8800656483137974\n",
      "loop number 36 RMSE: 0.879892755740375\n",
      "loop number 37 RMSE: 0.8797313499084264\n",
      "loop number 38 RMSE: 0.8795805306191636\n",
      "loop number 39 RMSE: 0.8794395186699112\n",
      "loop number 40 RMSE: 0.8793076326026295\n",
      "loop number 41 RMSE: 0.8791842702808756\n",
      "loop number 42 RMSE: 0.8790688943155534\n",
      "loop number 43 RMSE: 0.8789610205501213\n",
      "loop number 44 RMSE: 0.878860208970643\n",
      "loop number 45 RMSE: 0.8787660565319316\n",
      "loop number 46 RMSE: 0.8786781914932885\n",
      "loop number 47 RMSE: 0.8785962689401291\n",
      "loop number 48 RMSE: 0.8785199672346726\n",
      "loop number 49 RMSE: 0.8784489851926376\n",
      "loop number 50 RMSE: 0.8783830398258762\n",
      "loop number 51 RMSE: 0.8783218645252132\n",
      "loop number 52 RMSE: 0.8782652075848697\n",
      "loop number 53 RMSE: 0.8782128309913974\n",
      "loop number 54 RMSE: 0.87816450941695\n",
      "loop number 55 RMSE: 0.8781200293700542\n",
      "loop number 56 RMSE: 0.8780791884674991\n",
      "loop number 57 RMSE: 0.8780417947992141\n"
     ]
    }
   ],
   "source": [
    "totalRMSE = 0\n",
    "totalMAE = 0\n",
    "K, num_iter, r, l = 10, 75, 0.05, 0.005\n",
    "\n",
    "def converge_UM(X_train, X_test, U_i, M_i):\n",
    "    \"\"\"\n",
    "    With this function we iterate upon the element optimization of U and V, stopping when either the RMSE\n",
    "    falls below a chosen threshold or the improvement over the previous iteration becomes insignificant. \n",
    "    \"\"\"\n",
    "    count = 1 #count the number of iterations\n",
    "    \n",
    "\n",
    "    \n",
    "    #initialize the errors of the previous and current step such that the condition is held for the first loop \n",
    "    rmse_old = float('inf')\n",
    "    rmse_new = 10\n",
    "\n",
    "    #U_i, M_i  = init_UM(X_train, K)\n",
    "    \n",
    "    while (rmse_old - rmse_new > 1e-5) and count <= num_iter:\n",
    "        \n",
    "        \n",
    "        U,M = optimize_elements(X_train, K, num_iter, r, l, U_i, M_i)\n",
    "        P = np.matmul(U, M.T)\n",
    "        diff = X_test - P\n",
    "        rmse_old = rmse_new\n",
    "        rmse_new = np.sqrt(np.nanmean(diff**2)) #compute the Root-Mean Square Error between the two matrices M and P \n",
    "\n",
    "        if count_kfold==1:\n",
    "            RMSE_values1.append(rmse_new)\n",
    "        if count_kfold==2:\n",
    "            RMSE_values2.append(rmse_new)\n",
    "        if count_kfold==3:\n",
    "            RMSE_values3.append(rmse_new)\n",
    "        if count_kfold==4:\n",
    "            RMSE_values4.append(rmse_new)\n",
    "        if count_kfold==5:\n",
    "            RMSE_values5.append(rmse_new)\n",
    "        print('loop number {}'.format(count), \"RMSE:\", rmse_new)\n",
    "        count += 1\n",
    "        \n",
    "    return U,M,P, rmse_new #return the final, updated U and V\n",
    "\n",
    "\n",
    "RMSE_values1, RMSE_values2, RMSE_values3, RMSE_values4, RMSE_values5 = [], [], [], [], []\n",
    "\n",
    "count_kfold = 1\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=26)\n",
    "\n",
    "for train_index, test_index in kf.split(ratingsData):\n",
    "    print(\"\\nFold number:\", count_kfold)\n",
    "    now = datetime.datetime.now() #To check how long it takes to run \n",
    "    print (\"Time at start of fold number\", count_kfold, \" :\", now.strftime(\"%Y-%m-%d %H:%M:%S\"))   \n",
    "    \n",
    "    train_set = ratingsData.iloc[train_index]\n",
    "    test_set = ratingsData.iloc[test_index]\n",
    "    \n",
    "    # Save the user and movie IDs from the training/test set of this fold, for data visualisation later! \n",
    "    userIDs = df_train.index.values #test and train IDs are equivalent due to the condition above\n",
    "    movieIDs = df_train.columns.to_list()\n",
    "    np.save(\"userID_fold\"+str(count_kfold), userIDs)\n",
    "    np.save(\"movieID_fold\"+str(count_kfold), movieIDs)\n",
    "    \n",
    "    #First, determine the common set of movies and users in both sets\n",
    "    common_users = np.intersect1d(train_set['UserID'], test_set['UserID'])\n",
    "    common_movies = np.intersect1d(train_set['MovieID'], test_set['MovieID'])\n",
    "\n",
    "    # Filter the data to include only the common movies and users\n",
    "    train_set = train_set[(train_set['UserID'].isin(common_users)) & (train_set['MovieID'].isin(common_movies))]\n",
    "    test_set = test_set[(test_set['UserID'].isin(common_users)) & (test_set['MovieID'].isin(common_movies))]\n",
    "\n",
    "    # Convert data into a numpy array\n",
    "    df_train = train_set.pivot(index=\"UserID\", columns=\"MovieID\", values=\"Rating\")\n",
    "    df_test = test_set.pivot(index=\"UserID\", columns=\"MovieID\", values=\"Rating\")\n",
    "    X_train = np.array(df_train.to_numpy())\n",
    "    X_test = np.array(df_test.to_numpy())\n",
    "    \n",
    "    print(\"Training set:\")\n",
    "    print(X_train)\n",
    "    print(\"Test set:\")\n",
    "    print(X_test)\n",
    "\n",
    "    U_i, M_i = init_UM(X_train, K)\n",
    "    U, M, P, rmse = converge_UM(X_train, X_test, U_i, M_i)\n",
    "    print(\"Training matrix M:\\n\", X_train)\n",
    "    print(\"Predicted matrix P:\\n\", P)\n",
    "\n",
    "    print(\"MAE estimate of fold number \", count_kfold, \": \", rmse**2)\n",
    "    print(\"RMSE estimate of fold number \", count_kfold, \": \", rmse)\n",
    "    \n",
    "    \n",
    "    totalRMSE += rmse\n",
    "    totalMAE += rmse**2\n",
    "    \n",
    "\n",
    "    np.save(\"predicted_U_\"+str(count_kfold), U)\n",
    "    np.save(\"predicted_M_\"+str(count_kfold), M)\n",
    "    count_kfold += 1\n",
    "    \n",
    "\n",
    "# Calculate the average RMSE over all folds\n",
    "averageRMSE = totalRMSE / 5\n",
    "averageMAE = totalMAE / 5\n",
    "\n",
    "print(\"The Average MAE is\", averageMAE)\n",
    "print(\"The Average RMSE is\", averageRMSE)\n",
    "print(\"All RMSE values:\\n\")\n",
    "print(RMSE_values1, RMSE_values2, RMSE_values3, RMSE_values4, RMSE_values5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7099945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6065bb31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67347223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dec413e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853933ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94716d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
